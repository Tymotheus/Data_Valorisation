---
title: "How do education and social features affect STEM salaries? "
output:
  pdf_document: default
  html_document:
    df_print: paged
---

## Introduction

This notebook is the second delivery for Valorization des doneés course, in Université Cote de Azur, Nice (2023) . You can watch the explanation for the aim of the project and the data cleaning [here](https://www.youtube.com/watch?v=QIKk9Wc0Io89).

-   Business goal: Analyze how social features( race, gender)and education affect STEM salaries.

-   Technical goal: Perform regression to predict total yearly income

## Authors

Tymoteusz Igor Ciesielski [*tymoteusz-igor.ciesielski\@etu.univ-cotedazur.fr*](mailto:tymoteusz-igor.ciesielski@etu.univ-cotedazur.fr){.email}

Lucia Trillo Carreras [*lucia.trillo-carreras\@etu.univ-cotedazur.fr*](mailto:lucia.trillo-carreras@etu.univ-cotedazur.fr){.email}

Ewa Kupczyk [*ewa.kupczyk\@etu.univ-cotedazur.fr*](mailto:ewa.kupczyk@etu.univ-cotedazur.fr){.email}

Marina Bueno Garcia [*marina.bueno-garcia\@etu.univ-cotedazur.fr*](mailto:marina.bueno-garcia@etu.univ-cotedazur.fr){.email}

## Libraries

```{r}
library(tidyverse)
library(ggplot2)
library(plotly) #interactive visualisation
library(lattice) #data exploration (corellations)
library(dplyr)
library(countrycode) # For adding continent variable
library(corrplot)
library(rpart)
library(rpart.plot)
library(e1071)
library(plot3D)
```

## Data

The salary dataset we have used is scraped from Levels Fyi, a US-based online service for compensation comparison across companies in Tech. The dataset contains 62 642 samples and 29 variables.  Taking into consideration the type of data we can distinguish:

-   12 categorical nominal variables

-   6 categorical ordinal variables

-   2 numerical discrete variables and  4 numerical continuous variables

To check the detailed preprocessing, see \*notebookfirstdelivery.Rmd\* in the same repo.

We import our cleaned dataset from the first delivery

```{r}

#Dataset with all the variables
df_onehot <- read.csv('/Users/ltcmu/OneDrive/Documentos/Master/Data Valorisation/Proyecto/clean_salary_data.csv')
df_onehot <- na.omit(df_onehot) #Ensure we dont have NA values

#Dataset with Race, Gender and Education
df_social<-df_onehot[c("totalyearlycompensation","ed_master","ed_doctor","race_asian","race_hispanic","race_black","race_two_or_more","gender_female","gender_other")]
df_social <- na.omit(df_social) #Ensure we dont have NA values
```

We will feed our regression model with the one-hot encoded variables, having previously eliminating those with high correlation.

```{r}
df_onehot
dim(df_onehot)
```

We define our output variable Y:

```{r}
Y <- df_onehot[c("totalyearlycompensation")]
df_onehot <- subset(df_onehot, select = -c(totalyearlycompensation))
```

We split the data into training and testing sets

```{r}
set.seed(123)
trainIndex <- sample(1:nrow(df_onehot), 0.7 * nrow(df_onehot))
Ytrain <- Y[trainIndex,]
trainData <- df_onehot[trainIndex,]
Ytest <- Y[-trainIndex,]
testData <- df_onehot[-trainIndex,]
```

## LINEAR REGRESSION

Fit the linear regression model using the training and predict using the testing data.

```{r}
linearModel <- lm(Ytrain ~ ., data = trainData)
predictions <- predict(linearModel, newdata = testData)
```

Evaluate our model plotting the residuals and calculating the MSE:

```{r}
residuals <- Ytest - predictions
plot(residuals ~ predictions, xlab = "Predictions", ylab = "Residuals",
     main = "Residuals vs. Predictions")
abline(h = 0, col = "red")

mse <- mean(residuals^2)
cat("Mean Squared Error:", mse, "\n")

summary(Y)
```

Finally, we analyze the model:

```{r}
summary(linearModel)
```

## SVR

SVR is a type of supervised machine learning algorithm used for classification and regression analysis.

We implement 6 different models:

-   Linear kernel + nu-regression

```{r}
svmModel_nu <- svm(Ytrain ~ ., data = trainData, kernel = "linear", type = "nu-regression")

summary(svmModel_nu)
coef(svmModel_nu)

# Test your SVM model on the testing set
svmPred_nu <- predict(svmModel_nu, testData)

# Evaluate the accuracy of your SVM model: RMSE
RMSE_nu <- sqrt(mean((svmPred_nu - Ytest)^2))
RMSE_nu
```

-   Linear kernel + eps-regression

```{r}
svmModel_eps <- svm(Ytrain ~ ., data = trainData, kernel = "linear", type="eps-regression")
summary(svmModel_eps)
coef(svmModel_eps)
svmPred_eps <- predict(svmModel_eps, testData)
RMSE_eps <- sqrt(mean((svmPred_eps - Ytest)^2))
RMSE_eps
```

-   Radial kernel + nu-regression

```{r}
svmModel_nu_ra <- svm(Ytrain ~ ., data = trainData, kernel = "radial",type = "nu-regression")
summary(svmModel_nu_ra)
svmPred_nu_ra <- predict(svmModel_nu_ra, testData)
RMSE_nu_ra <- sqrt(mean((svmPred_nu_ra - Ytest)^2))
RMSE_nu_ra
```

-   Radial kernel + eps-regression

```{r}
svmModel_eps_ra <- svm(Ytrain ~ ., data = trainData, kernel = "radial", type = "eps-regression")
summary(svmModel_eps_ra)
svmPred_eps_ra <- predict(svmModel_eps_ra, testData)
RMSE_eps_ra <- sqrt(mean((svmPred_eps_ra - Ytest)^2))
RMSE_eps_ra
```

-   Polynomial kernel + nu-regression

```{r}
svmModel_nu_po <- svm(Ytrain ~ ., data = trainData, kernel = "polynomial", type = "nu-regression")
summary(svmModel_nu_po)
svmPred_nu_po <- predict(svmModel_nu_po, testData)
RMSE_nu_po <- sqrt(mean((svmPred_nu_po - Ytest)^2))
RMSE_nu_po
```

-   Polynomial kernel + eps-regression

```{r}
svmModel_eps_po <- svm(Ytrain ~ ., data = trainData, kernel = "polynomial", type = "eps-regression")
summary(svmModel_eps_po)
svmPred_eps_po <- predict(svmModel_eps_po, testData)
RMSE_eps_po <- sqrt(mean((svmPred_eps_po - Ytest)^2))
RMSE_eps_po
```

The model with the lowest RMSE is svmModel_nu_ra (radial kernel + nu-regression), followed closely by svmModel_nu (linear kernel + nu-regression).

The residual plot of this model is:

```{r}
residuals <- Ytest - svmPred_nu_ra
plot(svmPred_nu_ra, residuals, main="Residual Plot", xlab="Predicted Values", ylab="Residuals")
plot(Ytest,residuals, main="Residual Plot (radial + nu regression)", xlab="Test Values", ylab="Residuals")
abline(h = 0, col = "red")
```

And the Predicted vs Actual Values graph is:

```{r}
lims <- range(c(Ytest, svmPred_nu_ra))
plot(Ytest, svmPred_nu_ra, main = "Predicted vs Actual Values (radial + nu regression)", xlab = "Actual Values", ylab = "Predicted Values", xlim = lims, ylim = lims)
abline(0, 1, col = "red")
```

To have an idea of how good/bad our results are, let's have a look at the summary of the output variable

```{r}
summary(Ytest)
```

We calculate the R-squared value of our best model:

```{r}
R2_nu_ra <- 1 - sum((Ytest - svmPred_nu_ra)^2) / sum((Ytest - mean(Ytest))^2)
R2_nu_ra
```

This graph compares the real salary values and predictions for the four models:

```{r}
# Create a data frame with the scaled salaries and predictions
dfgraph <- data.frame(scaled_salaries = Ytest, pred_nu =svmPred_nu, pred_eps =svmPred_eps,pred_nu_ra=svmPred_nu_ra,pred_eps_ra=svmPred_eps_ra)

# Sort the data frame by the scaled salaries for plotting
dfgraph <- dfgraph[order(dfgraph$scaled_salaries), ]

# Create a line plot of the scaled salaries and predictions

plot_ly(dfgraph, x = ~scaled_salaries) %>%
 add_lines(y = ~pred_eps, name = "Linear kernel + nu-regression", line = list(color = "red", width = 2)) %>%
  add_lines(y = ~pred_nu_ra, name = "Linear kernel + eps-regression", line = list(color = "green", width = 2)) %>%
  add_lines(y = ~pred_eps_ra, name = "Radial kernel + nu-regression", line = list(color = "blue", width = 2)) %>%
  add_lines(y = ~pred_eps_ra, name = "Radial kernel + eps-regression", line = list(color = "yellow", width = 2)) %>%
  layout(xaxis = list(title = "Real scaled Salaries"), yaxis = list(title = "Predicted scaled Salaries"), ylim = c(0, 6))


```
